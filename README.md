# [IEEE Pacific Visualization 2025] Explorable INR: An Implicit Neural Representation for Ensemble Simulation Enabling Efficient Spatial and Parameter Exploration
by Yi-Tang Chen, Haoyu Li, Neng Shi, Xihaier Luo, Wei Xu, Han-Wei Shen.

The paper can be found at [arXiv](https://arxiv.org/abs/2504.00904).

## Abstract

With the growing computational power available for high-resolution ensemble simulations in scientific fields such as cosmology and oceanology, storage and computational demands present significant challenges. Current surrogate models fall short in the flexibility of point- or region-based predictions as the entire field reconstruction is required for each parameter setting, hence hindering the efficiency of parameter space exploration. Limitations exist in capturing physical attribute distributions and pinpointing optimal parameter configurations. In this work, we propose Explorable INR, a novel implicit neural representation-based surrogate model, designed to facilitate exploration and allow point-based spatial queries without computing full-scale field data. In addition, to further address computational bottlenecks of spatial exploration, we utilize probabilistic affine forms (PAFs) for uncertainty propagation through Explorable INR to obtain statistical summaries, facilitating various ensemble analysis and visualization tasks that are expensive with existing models. Furthermore, we reformulate the parameter exploration problem as optimization tasks using gradient descent and KL divergence minimization that ensures scalability. We demonstrate that the Explorable INR with the proposed approach for spatial and parameter exploration can significantly reduce computation and memory costs while providing effective ensemble analysis.

## Getting Started
This GitHub includes the model point query training and testing.

Our code is tested on `Linux` with `CUDA 11.8`, `Python 3.9.18`, and `PyTorch 2.4.1`.

The MPAS-Ocean testing dataset is available [here](https://drive.google.com/drive/folders/1R4nEgkBfjEtFWfm5DeNsENQjFKIMQqHw?usp=sharing), which comes from [GNN-Surrogate](https://github.com/trainsn/GNN-Surrogate).

The model weights can be found [here](https://drive.google.com/drive/folders/1IN_CQuZuXU9UTVpoq_9e6e3hIfYunVdX?usp=sharing).

Before running the script, ensure the folder path is set correctly. Modify the following path in `train.sh` and `test.sh`.

```
--root /path/to/data/ --dir-weights /path/to/weights/ --dir-outputs /path/to/outputs/
```

Run the script to train the model.

```
$ sh train.sh
```

Use the script to test the model.

```
$ sh test.sh
```

## Quantitative Results

The proposed INR and other INR methods are evaluated Nyx and MPAS-Oceandatasets. PSNR and MD are selected as the data-level metrics for the comparison between the Explorable INR and other INR methods: Instant-NGP, K-Planes, and CoordNet.

<p align="center">
<img src=".\imgs\quantitative.png" height = "250" alt="" align=center />
<br><br>
<b>Table 3.</b> Model performance.
</p>

## Qualitative Results

The comparison of images generated by the Explorable INR, VDL-Surrogate, InSituNet, Instant-NGP, and K-Planes for the Nyx dataset against the ground truth image is presented. The red box highlights the intricate details in the Nyx data. The blue/red points stand for the voxel difference between the ground truth and the reconstructed field.

<p align="center">
<img src=".\imgs\qualitative.png" height = "1000" alt="" align=center />
<br><br>
<b>Figure 4.</b> Showcases.
</p>

## Citation

If you use this code for your research, please cite our paper. The IEEE TVCG publication will update soon.
```
@article{chen2025explorable,
  title={Explorable INR: An Implicit Neural Representation for Ensemble Simulation Enabling Efficient Spatial and Parameter Exploration},
  author={Chen, Yi-Tang and Li, Haoyu and Shi, Neng and Luo, Xihaier and Xu, Wei and Shen, Han-Wei},
  journal={arXiv preprint arXiv:2504.00904},
  year={2025}
}
```

## Contact

If you have any questions, please contact [chen.10522@buckeyemail.osu.edu](chen.10522@buckeyemail.osu.edu)
